**Running the demo:**

```
As a temporary workaround to get the model weights

# run the following from root 
# git checkout gpt2-onnx
cd models/Xenova
git clone https://huggingface.co/Xenova/all-MiniLM-L6-v2
```

``` 
npm install -g http-server
http-server -p 8081 --cors
```



